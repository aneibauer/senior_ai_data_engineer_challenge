# ğŸš€ Quick Start Guide

This guide walks you through setting up and running the full system locally from scratch.

â¸»

## ğŸ§° Prerequisites

Before starting, ensure you have the following installed:

	â€¢	Docker Desktop
	â€¢	Docker Compose
	â€¢	Python 3.10+ (for local scripts and development)
	â€¢	Git

## ğŸ§¾ 1. Clone the Repository

```bash
git@github.com:your_username/senior_ai_data_engineer_challenge.git
cd senior_ai_data_engineer_challenge
```

## ğŸ“ 2. Create Required Local Directories

Some Spark services expect local bind-mounted folders. They should be created automatically by docker but just in case:

```bash
mkdir spark_output
mkdir spark_checkpoints
```

## ğŸ³ 3. Start All Services

Run the following command from the root of the project:

```bash
docker compose up --build
```
This will start the following containers:

	â€¢	pulsar: Message broker
	â€¢	postgres: Database with volume persistence
	â€¢	spark: Streaming job to consume Pulsar messages
	â€¢	spark-batch: Batch job that loads parquet files into Postgres
	â€¢	data-generator: Publishes synthetic event data to Pulsar
	â€¢	fastapi: REST API to query metrics from Postgres

Wait until all services show â€œhealthyâ€ or are idle/stable in logs.

## âœ… 4. Verify the FastAPI App

Once the FastAPI container is running, open your browser:
```
http://localhost:8000/docs
```
You should see the Swagger UI with interactive documentation.


â¸»

## ğŸ” 5. Test the API (Curl)

Try querying metrics for a valid tenant (e.g. merchant_1) via curl:

```bash
curl -H "Authorization: admin-token" "http://localhost:8000/api/v2/analytics/realtime/metrics?tenant_id=merchant_1&timeframe=1d"
```

Expected output:
```json
{
  "tenant_id": "merchant_1",
  "event_count": 3, <-will change depending on actual count of events
  "timeframe": "1d"
}
```
If you try querying with an unauthorized token (e.g. tenant1-token for a different tenant), you should receive a 403 Forbidden.

## ğŸ”š Thatâ€™s It!

Youâ€™ve now:
	â€¢	Bootstrapped the full architecture
	â€¢	Sent test event data via Pulsar
	â€¢	Stored enriched data in Postgres
	â€¢	Queried real-time metrics via FastAPI


## ğŸ› ï¸ If you need some troublshooting tips, see the troubleshooting_guide